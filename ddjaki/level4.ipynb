{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "21763764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "694ce5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main = pd.read_csv('data/ddakji_level_4_main_train.csv')\n",
    "test_main = pd.read_csv('data/ddakji_level_4_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9ca0f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = 'postgresql://td_participant:datathon!@45.79.28.247:5432/ddakji_db'\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c9dd1e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables available in the database:\n",
      "- level4\n",
      "- level5\n"
     ]
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "print(\"Tables available in the database:\")\n",
    "for table in table_names:\n",
    "    print(f\"- {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "313c48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_supp = pd.read_sql('SELECT * FROM level4', engine)\n",
    "\n",
    "# Merge training datasets\n",
    "train_merged = pd.merge(train_main, train_supp, on='Throw_IDs', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3db2fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged['Times_Practiced'] = train_merged.apply(\n",
    "    lambda row: row['Times_Practiced_x'] \n",
    "                if row['Times_Practiced_x'] == row['Times_Practiced_y'] \n",
    "                else row['Times_Practiced_x'],\n",
    "    axis=1\n",
    ")\n",
    "train_merged.drop(columns=['Times_Practiced_x', 'Times_Practiced_y'], inplace=True)\n",
    "\n",
    "# --- Step 5: Match columns in test (without target) carefully ---\n",
    "missing_cols_in_test = set(train_merged.columns) - set(test_main.columns) - {'Flip_Result'}\n",
    "for col in missing_cols_in_test:\n",
    "    if train_merged[col].dtype in ['float64', 'int64']:\n",
    "        test_main[col] = train_merged[col].median()\n",
    "    else:\n",
    "        test_main[col] = 'Unknown'\n",
    "\n",
    "# Fix \"Times_Practiced\" in test_main explicitly if needed\n",
    "if 'Times_Practiced_x' in test_main.columns:\n",
    "    test_main.rename(columns={'Times_Practiced_x': 'Times_Practiced'}, inplace=True)\n",
    "\n",
    "test_main = test_main[train_merged.drop(columns='Flip_Result').columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ded36c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Throw_IDs</th>\n",
       "      <th>Player_Consistency_Score</th>\n",
       "      <th>Cumulative_Impact_Force</th>\n",
       "      <th>Throws_Per_Week</th>\n",
       "      <th>Throw_Technique_Style</th>\n",
       "      <th>Player_Experience_Level</th>\n",
       "      <th>Throw_Accuracy_Deviation</th>\n",
       "      <th>Flip_Result</th>\n",
       "      <th>Times_Adjusted_Grip</th>\n",
       "      <th>Impact_Point</th>\n",
       "      <th>Times_Practiced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>751.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Rookie (0-25)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Face_Hit</td>\n",
       "      <td>95248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101073</td>\n",
       "      <td>32.0</td>\n",
       "      <td>972.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Quick_Flick</td>\n",
       "      <td>Veteran (46-65)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edge_Hit</td>\n",
       "      <td>28826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Corner_Hit</td>\n",
       "      <td>91146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101077</td>\n",
       "      <td>12.0</td>\n",
       "      <td>556.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Calculated_Lob</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edge_Hit</td>\n",
       "      <td>41586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100872</td>\n",
       "      <td>34.0</td>\n",
       "      <td>835.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Corner_Hit</td>\n",
       "      <td>135391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102922</td>\n",
       "      <td>32.0</td>\n",
       "      <td>158.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Veteran (46-65)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Face_Hit</td>\n",
       "      <td>127876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100113</td>\n",
       "      <td>39.0</td>\n",
       "      <td>998.26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Corner_Hit</td>\n",
       "      <td>423038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102373</td>\n",
       "      <td>26.0</td>\n",
       "      <td>487.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Calculated_Lob</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Corner_Hit</td>\n",
       "      <td>200880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100812</td>\n",
       "      <td>36.0</td>\n",
       "      <td>966.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Calculated_Lob</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Edge_Hit</td>\n",
       "      <td>362926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103089</td>\n",
       "      <td>59.0</td>\n",
       "      <td>663.87</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Calculated_Lob</td>\n",
       "      <td>Veteran (46-65)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Face_Hit</td>\n",
       "      <td>314695.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Throw_IDs  Player_Consistency_Score  Cumulative_Impact_Force  \\\n",
       "0     102500                      14.0                   751.00   \n",
       "1     101073                      32.0                   972.00   \n",
       "2     100095                       5.0                   164.00   \n",
       "3     101077                      12.0                   556.00   \n",
       "4     100872                      34.0                   835.00   \n",
       "5     102922                      32.0                   158.00   \n",
       "6     100113                      39.0                   998.26   \n",
       "7     102373                      26.0                   487.00   \n",
       "8     100812                      36.0                   966.48   \n",
       "9     103089                      59.0                   663.87   \n",
       "\n",
       "   Throws_Per_Week Throw_Technique_Style Player_Experience_Level  \\\n",
       "0              7.0           Steady_Push           Rookie (0-25)   \n",
       "1             23.0           Quick_Flick         Veteran (46-65)   \n",
       "2              7.0           Steady_Push     Experienced (26-45)   \n",
       "3             16.0        Calculated_Lob     Experienced (26-45)   \n",
       "4             13.0           Steady_Push     Experienced (26-45)   \n",
       "5              2.0           Steady_Push         Veteran (46-65)   \n",
       "6             17.0           Steady_Push     Experienced (26-45)   \n",
       "7             27.0        Calculated_Lob     Experienced (26-45)   \n",
       "8             22.0        Calculated_Lob     Experienced (26-45)   \n",
       "9             18.0        Calculated_Lob         Veteran (46-65)   \n",
       "\n",
       "   Throw_Accuracy_Deviation Flip_Result  Times_Adjusted_Grip Impact_Point  \\\n",
       "0                      10.0         Yes                  5.0     Face_Hit   \n",
       "1                       0.0         Yes                  5.0     Edge_Hit   \n",
       "2                       0.0         Yes                  4.0   Corner_Hit   \n",
       "3                       1.0         Yes                  5.0     Edge_Hit   \n",
       "4                      23.0         Yes                  1.0   Corner_Hit   \n",
       "5                       0.0         Yes                  1.0     Face_Hit   \n",
       "6                       3.0          No                  0.0   Corner_Hit   \n",
       "7                       7.0         Yes                  0.0   Corner_Hit   \n",
       "8                      18.0          No                  1.0     Edge_Hit   \n",
       "9                       1.0          No                  4.0     Face_Hit   \n",
       "\n",
       "   Times_Practiced  \n",
       "0          95248.0  \n",
       "1          28826.0  \n",
       "2          91146.0  \n",
       "3          41586.0  \n",
       "4         135391.0  \n",
       "5         127876.0  \n",
       "6         423038.0  \n",
       "7         200880.0  \n",
       "8         362926.0  \n",
       "9         314695.0  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fa6ce1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_cols_in_test = set(train_merged.columns) - set(test_main.columns) - {'Flip_Result'}\n",
    "# for col in missing_cols_in_test:\n",
    "#     test_main[col] = 0  # default numeric fill (0 is usually fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e51f456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_main = test_main[train_merged.drop(columns='Flip_Result').columns]\n",
    "categorical_cols = ['Throw_Technique_Style', 'Player_Experience_Level', 'Impact_Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "82439399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Throw_IDs</th>\n",
       "      <th>Player_Consistency_Score</th>\n",
       "      <th>Cumulative_Impact_Force</th>\n",
       "      <th>Throws_Per_Week</th>\n",
       "      <th>Throw_Technique_Style</th>\n",
       "      <th>Player_Experience_Level</th>\n",
       "      <th>Throw_Accuracy_Deviation</th>\n",
       "      <th>Times_Adjusted_Grip</th>\n",
       "      <th>Impact_Point</th>\n",
       "      <th>Times_Practiced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100439</td>\n",
       "      <td>24.0</td>\n",
       "      <td>692.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Quick_Flick</td>\n",
       "      <td>Veteran (46-65)</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Face_Hit</td>\n",
       "      <td>164271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100206</td>\n",
       "      <td>47.0</td>\n",
       "      <td>656.42</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Calculated_Lob</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Face_Hit</td>\n",
       "      <td>333724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100375</td>\n",
       "      <td>19.0</td>\n",
       "      <td>567.61</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Veteran (46-65)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Corner_Hit</td>\n",
       "      <td>427302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100561</td>\n",
       "      <td>20.0</td>\n",
       "      <td>997.47</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Edge_Hit</td>\n",
       "      <td>397029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100493</td>\n",
       "      <td>36.0</td>\n",
       "      <td>329.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Steady_Push</td>\n",
       "      <td>Experienced (26-45)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edge_Hit</td>\n",
       "      <td>44943.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Throw_IDs  Player_Consistency_Score  Cumulative_Impact_Force  \\\n",
       "0     100439                      24.0                   692.00   \n",
       "1     100206                      47.0                   656.42   \n",
       "2     100375                      19.0                   567.61   \n",
       "3     100561                      20.0                   997.47   \n",
       "4     100493                      36.0                   329.00   \n",
       "\n",
       "   Throws_Per_Week Throw_Technique_Style Player_Experience_Level  \\\n",
       "0              7.0           Quick_Flick         Veteran (46-65)   \n",
       "1             27.0        Calculated_Lob     Experienced (26-45)   \n",
       "2             29.0           Steady_Push         Veteran (46-65)   \n",
       "3             16.0           Steady_Push     Experienced (26-45)   \n",
       "4             30.0           Steady_Push     Experienced (26-45)   \n",
       "\n",
       "   Throw_Accuracy_Deviation  Times_Adjusted_Grip Impact_Point  Times_Practiced  \n",
       "0                      29.0                  9.0     Face_Hit         164271.0  \n",
       "1                      15.0                  0.0     Face_Hit         333724.0  \n",
       "2                       8.0                  1.0   Corner_Hit         427302.0  \n",
       "3                       0.0                  1.0     Edge_Hit         397029.0  \n",
       "4                      23.0                  5.0     Edge_Hit          44943.0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6587d3",
   "metadata": {},
   "source": [
    "Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b04a0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train_merged.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_cols.remove('Throw_IDs')  # ID shouldn't be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "224a0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_merged, test_main], keys=['train', 'test'])\n",
    "# one hot\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "914663ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = combined_df_encoded.loc['train'].copy()\n",
    "test_encoded = combined_df_encoded.loc['test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b149fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_cols.remove('Throw_IDs')  # Don't impute Throw_IDs.\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "train_encoded.loc[:, numeric_cols] = imputer.fit_transform(train_encoded.loc[:, numeric_cols])\n",
    "test_encoded.loc[:, numeric_cols] = imputer.transform(test_encoded.loc[:, numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a0c50963",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded['Flip_Result'] = train_encoded['Flip_Result'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# --- Step 11: Ensure no NaNs in target ---\n",
    "train_encoded = train_encoded.dropna(subset=['Flip_Result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "28ff24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_encoded.drop(columns=['Throw_IDs', 'Flip_Result'])\n",
    "y_train = train_encoded['Flip_Result']\n",
    "\n",
    "X_test = test_encoded.drop(columns=['Throw_IDs', 'Flip_Result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8f204da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=150,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=150,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=150,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=150, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4ee8dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Accuracy: 100.00%\n",
      "✅ Submission CSV created successfully!\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, train_preds)\n",
    "print(f\"✅ Training Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Step 12: Make predictions for test set\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds_labels = ['Yes' if pred == 1 else 'No' for pred in test_preds]\n",
    "\n",
    "# Step 13: Export submission CSV\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': test_preds_labels\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Submission CSV created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4b109",
   "metadata": {},
   "source": [
    "### DB DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "63c68d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Throw_IDs  Times_Practiced_x  Player_Consistency_Score  \\\n",
      "0     102500            95248.0                      14.0   \n",
      "1     101073            28826.0                      32.0   \n",
      "2     100095            91146.0                       5.0   \n",
      "3     101077            41586.0                      12.0   \n",
      "4     100872           135391.0                      34.0   \n",
      "\n",
      "   Cumulative_Impact_Force  Throws_Per_Week Throw_Technique_Style  \\\n",
      "0                    751.0              7.0           Steady_Push   \n",
      "1                    972.0             23.0           Quick_Flick   \n",
      "2                    164.0              7.0           Steady_Push   \n",
      "3                    556.0             16.0        Calculated_Lob   \n",
      "4                    835.0             13.0           Steady_Push   \n",
      "\n",
      "  Player_Experience_Level  Throw_Accuracy_Deviation Flip_Result  \\\n",
      "0           Rookie (0-25)                      10.0         Yes   \n",
      "1         Veteran (46-65)                       0.0         Yes   \n",
      "2     Experienced (26-45)                       0.0         Yes   \n",
      "3     Experienced (26-45)                       1.0         Yes   \n",
      "4     Experienced (26-45)                      23.0         Yes   \n",
      "\n",
      "   Times_Practiced_y  Times_Adjusted_Grip Impact_Point  \n",
      "0            95248.0                  5.0     Face_Hit  \n",
      "1            28826.0                  5.0     Edge_Hit  \n",
      "2            91146.0                  4.0   Corner_Hit  \n",
      "3            41586.0                  5.0     Edge_Hit  \n",
      "4           135391.0                  1.0   Corner_Hit  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3200 entries, 0 to 3199\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Throw_IDs                 3200 non-null   int64  \n",
      " 1   Times_Practiced_x         3200 non-null   float64\n",
      " 2   Player_Consistency_Score  3183 non-null   float64\n",
      " 3   Cumulative_Impact_Force   3178 non-null   float64\n",
      " 4   Throws_Per_Week           3182 non-null   float64\n",
      " 5   Throw_Technique_Style     3183 non-null   object \n",
      " 6   Player_Experience_Level   3183 non-null   object \n",
      " 7   Throw_Accuracy_Deviation  3184 non-null   float64\n",
      " 8   Flip_Result               3200 non-null   object \n",
      " 9   Times_Practiced_y         3200 non-null   float64\n",
      " 10  Times_Adjusted_Grip       3181 non-null   float64\n",
      " 11  Impact_Point              3189 non-null   object \n",
      "dtypes: float64(7), int64(1), object(4)\n",
      "memory usage: 300.1+ KB\n",
      "None\n",
      "Throw_IDs                    0\n",
      "Times_Practiced_x            0\n",
      "Player_Consistency_Score    17\n",
      "Cumulative_Impact_Force     22\n",
      "Throws_Per_Week             18\n",
      "Throw_Technique_Style       17\n",
      "Player_Experience_Level     17\n",
      "Throw_Accuracy_Deviation    16\n",
      "Flip_Result                  0\n",
      "Times_Practiced_y            0\n",
      "Times_Adjusted_Grip         19\n",
      "Impact_Point                11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to your database\n",
    "db_url = 'postgresql://td_participant:datathon!@45.79.28.247:5432/ddakji_db'\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Load main CSV\n",
    "train_main = pd.read_csv('data/ddakji_level_4_main_train.csv')\n",
    "\n",
    "# Load supplemental SQL data\n",
    "train_supp = pd.read_sql('SELECT * FROM level4', engine)\n",
    "\n",
    "# Merge datasets\n",
    "train_merged = pd.merge(train_main, train_supp, on='Throw_IDs', how='left')\n",
    "\n",
    "# Inspect merged DataFrame thoroughly\n",
    "print(train_merged.head())\n",
    "print(train_merged.info())\n",
    "print(train_merged.isnull().sum())\n",
    "\n",
    "# Save merged data temporarily if needed\n",
    "train_merged.to_csv('merged_train_debug.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b391bd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Accuracy: 100.00%\n",
      "✅ Submission CSV created successfully!\n",
      "Flip_Result\n",
      "Yes    466\n",
      "No     334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Step 1: Load Data ---\n",
    "train_main = pd.read_csv('data/ddakji_level_4_main_train.csv')\n",
    "test_main = pd.read_csv('data/ddakji_level_4_test.csv')\n",
    "\n",
    "# --- Step 2: SQL Connection & Supplemental Data ---\n",
    "db_url = 'postgresql://td_participant:datathon!@45.79.28.247:5432/ddakji_db'\n",
    "engine = create_engine(db_url)\n",
    "train_supp = pd.read_sql('SELECT * FROM level4', engine)\n",
    "\n",
    "# --- Step 3: Merge Supplemental Data ---\n",
    "train_merged = pd.merge(train_main, train_supp, on='Throw_IDs', how='left')\n",
    "\n",
    "# --- Step 4: Clearly Handle \"Times_Practiced\" ---\n",
    "train_merged['Times_Practiced'] = train_merged.apply(\n",
    "    lambda row: row['Times_Practiced_x'] \n",
    "                if row['Times_Practiced_x'] == row['Times_Practiced_y'] \n",
    "                else (row['Times_Practiced_x']),\n",
    "    axis=1\n",
    ")\n",
    "train_merged.drop(columns=['Times_Practiced_x', 'Times_Practiced_y'], inplace=True)\n",
    "\n",
    "# --- Step 5: Match columns in test (without target) carefully ---\n",
    "missing_cols_in_test = set(train_merged.columns) - set(test_main.columns) - {'Flip_Result'}\n",
    "for col in missing_cols_in_test:\n",
    "    if train_merged[col].dtype in ['float64', 'int64']:\n",
    "        test_main[col] = train_merged[col].median()\n",
    "    else:\n",
    "        test_main[col] = 'Unknown'\n",
    "\n",
    "# Fix \"Times_Practiced\" in test_main explicitly if needed\n",
    "if 'Times_Practiced_x' in test_main.columns:\n",
    "    test_main.rename(columns={'Times_Practiced_x': 'Times_Practiced'}, inplace=True)\n",
    "\n",
    "test_main = test_main[train_merged.drop(columns='Flip_Result').columns]\n",
    "\n",
    "# --- Step 6: Identify categorical columns explicitly ---\n",
    "categorical_cols = ['Throw_Technique_Style', 'Player_Experience_Level', 'Impact_Point']\n",
    "\n",
    "# --- Step 7: Combine datasets ---\n",
    "combined_df = pd.concat([train_merged, test_main], keys=['train', 'test'])\n",
    "\n",
    "# --- Step 8: One-Hot Encoding ---\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# --- Step 9: Split back explicitly ---\n",
    "train_encoded = combined_df_encoded.loc['train'].copy()\n",
    "test_encoded = combined_df_encoded.loc['test'].copy()\n",
    "\n",
    "# --- Step 10: Numeric columns and Imputation ---\n",
    "numeric_cols = train_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_cols.remove('Throw_IDs')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "train_encoded.loc[:, numeric_cols] = imputer.fit_transform(train_encoded.loc[:, numeric_cols])\n",
    "test_encoded.loc[:, numeric_cols] = imputer.transform(test_encoded.loc[:, numeric_cols])\n",
    "\n",
    "# --- Step 11: Encode target explicitly ---\n",
    "train_encoded['Flip_Result'] = train_encoded['Flip_Result'].map({'Yes': 1, 'No': 0})\n",
    "train_encoded = train_encoded.dropna(subset=['Flip_Result'])\n",
    "\n",
    "# --- Step 12: Prepare X and y explicitly ---\n",
    "X_train = train_encoded.drop(columns=['Throw_IDs', 'Flip_Result'])\n",
    "y_train = train_encoded['Flip_Result']\n",
    "X_test = test_encoded.drop(columns=['Throw_IDs', 'Flip_Result'], errors='ignore')\n",
    "\n",
    "# --- Step 13: Train model (balanced classes) ---\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Step 14: Verify accuracy ---\n",
    "train_preds = model.predict(X_train)\n",
    "print(f\"✅ Training Accuracy: {accuracy_score(y_train, train_preds):.2%}\")\n",
    "\n",
    "# --- Step 15: Generate predictions explicitly ---\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds_labels = ['Yes' if pred == 1 else 'No' for pred in test_preds]\n",
    "\n",
    "# --- Step 16: Export final submission ---\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': test_preds_labels\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Submission CSV created successfully!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8c617e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest Training Accuracy: 100.00%\n",
      "✅ Gradient Boosting Training Accuracy: 100.00%\n",
      "✅ Ensemble submission.csv created successfully!\n",
      "Flip_Result\n",
      "Yes    466\n",
      "No     334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- Step 13: Train both models ---\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# --- Step 14: Evaluate training performance of each model (optional) ---\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_preds_train = rf_model.predict(X_train)\n",
    "gb_preds_train = gb_model.predict(X_train)\n",
    "rf_acc = accuracy_score(y_train, rf_preds_train)\n",
    "gb_acc = accuracy_score(y_train, gb_preds_train)\n",
    "\n",
    "print(f\"✅ Random Forest Training Accuracy: {rf_acc:.2%}\")\n",
    "print(f\"✅ Gradient Boosting Training Accuracy: {gb_acc:.2%}\")\n",
    "\n",
    "# --- Step 15: Ensemble predictions on test set ---\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]  # Probability of class \"1\" (Yes)\n",
    "gb_probs = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Average the probabilities\n",
    "ensemble_probs = (rf_probs + gb_probs) / 2\n",
    "\n",
    "# Final prediction: probability > 0.5 → \"Yes\", otherwise \"No\"\n",
    "final_preds = ['Yes' if prob > 0.5 else 'No' for prob in ensemble_probs]\n",
    "\n",
    "# --- Step 16: Create final submission.csv ---\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Ensemble submission.csv created successfully!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d84811b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b9bdbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.clamp(min=1e-7, max=1 - 1e-7)  # avoid log(0)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.where(targets == 1, inputs, 1 - inputs)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * BCE\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "21a130e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Accuracy = 0.9812\n",
      "Epoch 2: Val Accuracy = 0.9250\n",
      "Epoch 3: Val Accuracy = 0.9646\n",
      "Epoch 4: Val Accuracy = 0.9708\n",
      "Epoch 5: Val Accuracy = 0.9208\n",
      "Epoch 6: Val Accuracy = 0.9542\n",
      "Epoch 7: Val Accuracy = 0.9688\n",
      "Epoch 8: Val Accuracy = 0.9875\n",
      "Epoch 9: Val Accuracy = 0.9667\n",
      "Epoch 10: Val Accuracy = 0.8833\n",
      "Epoch 11: Val Accuracy = 0.9792\n",
      "Epoch 12: Val Accuracy = 0.9875\n",
      "Epoch 13: Val Accuracy = 0.9646\n",
      "Epoch 14: Val Accuracy = 0.9417\n",
      "Epoch 15: Val Accuracy = 0.9458\n",
      "Epoch 16: Val Accuracy = 0.9729\n",
      "Epoch 17: Val Accuracy = 0.9792\n",
      "Epoch 18: Val Accuracy = 0.9667\n",
      "Early stopping triggered.\n",
      "✅ Neural network submission.csv created successfully!\n",
      "Flip_Result\n",
      "Yes    494\n",
      "No     306\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Convert your final cleaned data into tensors ---\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "# Split train into train/val\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_np, y_train_np, test_size=0.15, random_state=42)\n",
    "\n",
    "# Torch datasets\n",
    "train_ds = TensorDataset(torch.tensor(X_tr), torch.tensor(y_tr))\n",
    "val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "test_tensor = torch.tensor(X_test_np)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# --- Step 2: Define the neural network ---\n",
    "class FlipNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "# --- Step 3: Training Setup ---\n",
    "model = FlipNet(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = FocalLoss(alpha=0.15, gamma=2)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience, patience_limit = 0, 10\n",
    "\n",
    "# --- Step 4: Train the model ---\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(torch.tensor(X_val))\n",
    "        val_pred_labels = (val_preds.numpy() > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_val, val_pred_labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Val Accuracy = {acc:.4f}\")\n",
    "\n",
    "    # # Early stopping\n",
    "    # if acc > best_val_acc:\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_model_state = model.state_dict()\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= patience_limit:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Step 5: Load best model and predict on test set ---\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_probs = model(test_tensor).numpy().flatten()\n",
    "    test_labels = ['Yes' if p > 0.5 else 'No' for p in test_probs]\n",
    "\n",
    "# --- Step 6: Create submission.csv ---\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': test_labels\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Neural network submission.csv created successfully!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4e4db4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\VSC\\Competitions\\datathon25\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Accuracy = 0.9729\n",
      "Epoch 2: Val Accuracy = 0.9688\n",
      "Epoch 3: Val Accuracy = 0.9667\n",
      "Epoch 4: Val Accuracy = 0.9354\n",
      "Epoch 5: Val Accuracy = 0.9896\n",
      "Epoch 6: Val Accuracy = 0.9875\n",
      "Epoch 7: Val Accuracy = 0.9875\n",
      "Epoch 8: Val Accuracy = 0.9875\n",
      "Epoch 9: Val Accuracy = 0.9250\n",
      "Epoch 10: Val Accuracy = 0.9896\n",
      "Epoch 11: Val Accuracy = 0.9771\n",
      "Epoch 12: Val Accuracy = 0.9333\n",
      "Epoch 13: Val Accuracy = 0.9875\n",
      "Epoch 14: Val Accuracy = 0.9875\n",
      "Epoch 15: Val Accuracy = 0.9896\n",
      "Epoch 16: Val Accuracy = 0.9896\n",
      "Epoch 17: Val Accuracy = 0.9875\n",
      "Epoch 18: Val Accuracy = 0.9854\n",
      "Epoch 19: Val Accuracy = 0.9854\n",
      "Epoch 20: Val Accuracy = 0.9833\n",
      "✅ Early stopping triggered.\n",
      "✅ Neural network submission.csv created successfully!\n",
      "Flip_Result\n",
      "Yes    472\n",
      "No     328\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Focal Loss ---\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.clamp(min=1e-7, max=1 - 1e-7)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.where(targets == 1, inputs, 1 - inputs)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * BCE\n",
    "        return loss.mean()\n",
    "\n",
    "# --- Neural Network ---\n",
    "class FlipNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.drop3(x)\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "# --- Step 1: Preprocessing ---\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32).reshape(-1, 1)\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_np, y_train_np, test_size=0.15, random_state=42)\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_tr), torch.tensor(y_tr))\n",
    "val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "test_tensor = torch.tensor(X_test_np)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# --- Step 2: Training Setup ---\n",
    "model = FlipNet(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = FocalLoss(alpha=0.15, gamma=2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 0\n",
    "patience_limit = 15\n",
    "\n",
    "# --- Step 3: Training Loop ---\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        # Add tiny input noise for regularization\n",
    "        noise = torch.randn_like(xb) * 0.01\n",
    "        preds = model(xb + noise)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # --- Step 4: Validation ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(torch.tensor(X_val))\n",
    "        val_pred_labels = (val_preds.numpy() > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_val, val_pred_labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Val Accuracy = {acc:.4f}\")\n",
    "    scheduler.step(acc)\n",
    "\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_model_state = model.state_dict()\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= patience_limit:\n",
    "            print(\"✅ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Step 5: Load best model and predict on test set ---\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "# Enable MC Dropout during prediction for robustness\n",
    "def predict_mc_dropout(model, x_tensor, n=10):\n",
    "    model.train()  # force dropout ON\n",
    "    preds = [model(x_tensor).detach().numpy().flatten() for _ in range(n)]\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_probs = predict_mc_dropout(model, test_tensor, n=10)\n",
    "\n",
    "# --- Step 6: Threshold tuning ---\n",
    "threshold = 0.46  # tune this!\n",
    "test_labels = ['Yes' if p > threshold else 'No' for p in test_probs]\n",
    "\n",
    "# --- Step 7: Create submission.csv ---\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': test_labels\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Neural network submission.csv created successfully!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91894992",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e8c2e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBoost submission created!\n",
      "Flip_Result\n",
      "Yes    465\n",
      "No     335\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Set parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0,\n",
    "    'seed': 42,\n",
    "    \n",
    "}\n",
    "\n",
    "# Train the model\n",
    "booster = xgb.train(params, dtrain, num_boost_round=200)\n",
    "\n",
    "# Predict\n",
    "test_probs = booster.predict(dtest)\n",
    "test_preds = ['Yes' if p > 0.5 else 'No' for p in test_probs]\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],\n",
    "    'Flip_Result': test_preds\n",
    "})\n",
    "submission.to_csv('submission_xgboost.csv', index=False)\n",
    "print(\"✅ XGBoost submission created!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "915e91a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\VSC\\Competitions\\datathon25\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: NN Val Accuracy = 0.9771\n",
      "Epoch 2: NN Val Accuracy = 0.9667\n",
      "Epoch 3: NN Val Accuracy = 0.9646\n",
      "Epoch 4: NN Val Accuracy = 0.9250\n",
      "Epoch 5: NN Val Accuracy = 0.9563\n",
      "Epoch 6: NN Val Accuracy = 0.9458\n",
      "Epoch 7: NN Val Accuracy = 0.9833\n",
      "Epoch 8: NN Val Accuracy = 0.9875\n",
      "Epoch 9: NN Val Accuracy = 0.9667\n",
      "Epoch 10: NN Val Accuracy = 0.9896\n",
      "Epoch 11: NN Val Accuracy = 0.9667\n",
      "Epoch 12: NN Val Accuracy = 0.9375\n",
      "Epoch 13: NN Val Accuracy = 0.9125\n",
      "Epoch 14: NN Val Accuracy = 0.9167\n",
      "Epoch 15: NN Val Accuracy = 0.9292\n",
      "Epoch 16: NN Val Accuracy = 0.9854\n",
      "Epoch 17: NN Val Accuracy = 0.9854\n",
      "Epoch 18: NN Val Accuracy = 0.9688\n",
      "Epoch 19: NN Val Accuracy = 0.9833\n",
      "Epoch 20: NN Val Accuracy = 0.9854\n",
      "Epoch 21: NN Val Accuracy = 0.9833\n",
      "Epoch 22: NN Val Accuracy = 0.9854\n",
      "Epoch 23: NN Val Accuracy = 0.9875\n",
      "Epoch 24: NN Val Accuracy = 0.9833\n",
      "Epoch 25: NN Val Accuracy = 0.9854\n",
      "Epoch 26: NN Val Accuracy = 0.9854\n",
      "Epoch 27: NN Val Accuracy = 0.9854\n",
      "Epoch 28: NN Val Accuracy = 0.9875\n",
      "NN Early stopping triggered.\n",
      "✅ Ensemble submission created!\n",
      "Flip_Result\n",
      "Yes    466\n",
      "No     334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#############################################\n",
    "#           XGBoost Model Section           #\n",
    "#############################################\n",
    "\n",
    "# Prepare data for XGBoost\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "# Fix: Convert y_train to a NumPy array before reshaping\n",
    "y_train_np = y_train.values.astype(np.float32).reshape(-1, 1)\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_np, label=y_train_np)\n",
    "dtest = xgb.DMatrix(X_test_np)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0,\n",
    "    'seed': 42,\n",
    "}\n",
    "booster = xgb.train(params, dtrain, num_boost_round=200)\n",
    "xgb_probs = booster.predict(dtest)\n",
    "\n",
    "#############################################\n",
    "#        Neural Network Model Section       #\n",
    "#############################################\n",
    "\n",
    "# --- Focal Loss ---\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.15, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.clamp(min=1e-7, max=1 - 1e-7)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.where(targets == 1, inputs, 1 - inputs)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * BCE\n",
    "        return loss.mean()\n",
    "\n",
    "# --- Neural Network Architecture ---\n",
    "class FlipNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.drop3(x)\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "# Prepare data for the NN using the same NumPy arrays from above\n",
    "X_train_nn = X_train_np.copy()\n",
    "y_train_nn = y_train_np.copy()\n",
    "X_test_nn = X_test_np.copy()\n",
    "\n",
    "# Split training data into train/validation sets\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_nn, y_train_nn, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create PyTorch datasets and loaders\n",
    "train_ds = TensorDataset(torch.tensor(X_tr), torch.tensor(y_tr))\n",
    "val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "test_tensor = torch.tensor(X_test_nn)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# Initialize model, optimizer, loss function, and scheduler\n",
    "model = FlipNet(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = FocalLoss(alpha=0.15, gamma=2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 0\n",
    "patience_limit = 18\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        # Add a small amount of noise for regularization\n",
    "        noise = torch.randn_like(xb) * 0.01\n",
    "        preds = model(xb + noise)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(torch.tensor(X_val))\n",
    "        val_pred_labels = (val_preds.numpy() > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_val, val_pred_labels)\n",
    "    print(f\"Epoch {epoch+1}: NN Val Accuracy = {acc:.4f}\")\n",
    "    scheduler.step(acc)\n",
    "    \n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_model_state = model.state_dict()\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= patience_limit:\n",
    "            print(\"NN Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "# Enable MC Dropout for robust NN inference\n",
    "def predict_mc_dropout(model, x_tensor, n=10):\n",
    "    model.train()  # force dropout active during prediction\n",
    "    preds = [model(x_tensor).detach().numpy().flatten() for _ in range(n)]\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    nn_probs = predict_mc_dropout(model, test_tensor, n=10)\n",
    "\n",
    "#############################################\n",
    "#         Ensemble Predictions Section      #\n",
    "#############################################\n",
    "\n",
    "# Average the probabilities from XGBoost and the NN\n",
    "ensemble_probs = (xgb_probs*(0.95) + nn_probs*(1.05)) / 2\n",
    "threshold = 0.47  # Adjust the threshold as needed\n",
    "ensemble_preds = ['Yes' if p > threshold else 'No' for p in ensemble_probs]\n",
    "\n",
    "#############################################\n",
    "#         Submission CSV Generation         #\n",
    "#############################################\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],  # Ensure test_encoded has the 'Throw_IDs' column\n",
    "    'Flip_Result': ensemble_preds\n",
    "})\n",
    "submission.to_csv('submission_ensemble.csv', index=False)\n",
    "print(\"✅ Ensemble submission created!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n",
      "✅ Stacked ensemble submission created!\n",
      "Flip_Result\n",
      "Yes    466\n",
      "No     334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#############################################\n",
    "#           Data Preparation              #\n",
    "#############################################\n",
    "\n",
    "# Convert data to NumPy arrays (ensuring float32 for features and proper shape for target)\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32).reshape(-1, 1)  # Fixed: use .values then reshape\n",
    "X_test_np  = X_test.values.astype(np.float32)\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "#############################################\n",
    "#         Neural Network Setup            #\n",
    "#############################################\n",
    "\n",
    "# Focal Loss definition\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.15, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.clamp(min=1e-7, max=1 - 1e-7)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.where(targets == 1, inputs, 1 - inputs)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * BCE\n",
    "        return loss.mean()\n",
    "\n",
    "# Neural network architecture (FlipNet)\n",
    "class FlipNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.out = nn.Linear(32, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.drop3(x)\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "# Function to train the NN on a given fold\n",
    "def train_nn_on_fold(X_train_fold, y_train_fold, input_size, epochs=50):\n",
    "    X_train_fold_tensor = torch.tensor(X_train_fold)\n",
    "    y_train_fold_tensor = torch.tensor(y_train_fold)\n",
    "    dataset = TensorDataset(X_train_fold_tensor, y_train_fold_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    model = FlipNet(input_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    loss_fn = FocalLoss(alpha=0.15, gamma=2)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    best_model_state = None\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            noise = torch.randn_like(xb) * 0.01\n",
    "            preds = model(xb + noise)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(loader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model_state = model.state_dict()\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "# Function for Monte Carlo Dropout predictions\n",
    "def predict_mc_dropout(model, x_tensor, n=10):\n",
    "    model.train()  # force dropout to be active\n",
    "    preds = [model(x_tensor).detach().numpy().flatten() for _ in range(n)]\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "#############################################\n",
    "#       Out-of-Fold Stacking Setup        #\n",
    "#############################################\n",
    "\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "# Prepare an array to hold out-of-fold predictions for both models\n",
    "oof_preds = np.zeros((X_train_np.shape[0], 2))  # column 0: XGBoost; column 1: NN\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_np, y_train_np.ravel())):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_tr_fold = X_train_np[train_idx]\n",
    "    y_tr_fold = y_train_np[train_idx]\n",
    "    X_val_fold = X_train_np[val_idx]\n",
    "    y_val_fold = y_train_np[val_idx]\n",
    "    \n",
    "    # XGBoost for current fold\n",
    "    dtrain_fold = xgb.DMatrix(X_tr_fold, label=y_tr_fold)\n",
    "    booster_fold = xgb.train(params, dtrain_fold, num_boost_round=200)\n",
    "    oof_preds[val_idx, 0] = booster_fold.predict(xgb.DMatrix(X_val_fold))\n",
    "    \n",
    "    # Neural Network for current fold\n",
    "    nn_model_fold = train_nn_on_fold(X_tr_fold, y_tr_fold, input_size=X_train_np.shape[1], epochs=75)\n",
    "    X_val_fold_tensor = torch.tensor(X_val_fold)\n",
    "    oof_preds[val_idx, 1] = predict_mc_dropout(nn_model_fold, X_val_fold_tensor, n=10)\n",
    "\n",
    "# Train a meta-learner (logistic regression) on the out-of-fold predictions\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "meta_model.fit(oof_preds, y_train_np.ravel())\n",
    "\n",
    "#############################################\n",
    "#    Train Base Models on Full Training   #\n",
    "#############################################\n",
    "\n",
    "# XGBoost on full training data\n",
    "booster_full = xgb.train(params, xgb.DMatrix(X_train_np, label=y_train_np), num_boost_round=200)\n",
    "xgb_test_probs = booster_full.predict(xgb.DMatrix(X_test_np))\n",
    "\n",
    "# Neural Network on full training data\n",
    "nn_model_full = train_nn_on_fold(X_train_np, y_train_np, input_size=X_train_np.shape[1], epochs=75)\n",
    "nn_test_probs = predict_mc_dropout(nn_model_full, torch.tensor(X_test_np), n=10)\n",
    "\n",
    "# Stack the test predictions as features for the meta-learner\n",
    "stacked_test = np.column_stack((xgb_test_probs, nn_test_probs))\n",
    "meta_test_probs = meta_model.predict_proba(stacked_test)[:, 1]\n",
    "\n",
    "threshold = 0.48  # Adjust the threshold as needed\n",
    "final_preds = ['Yes' if p > threshold else 'No' for p in meta_test_probs]\n",
    "\n",
    "#############################################\n",
    "#       Generate Final Submission CSV       #\n",
    "#############################################\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Throw_IDs': test_encoded['Throw_IDs'],  # Ensure this DataFrame has the 'Throw_IDs'\n",
    "    'Flip_Result': final_preds\n",
    "})\n",
    "submission.to_csv('submission_stacked_ensemble.csv', index=False)\n",
    "print(\"✅ Stacked ensemble submission created!\")\n",
    "print(submission['Flip_Result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876554ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
